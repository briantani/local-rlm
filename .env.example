# ===========================
# LLM Provider Configuration
# ===========================

# Google Gemini API Key
# Get your key from: https://aistudio.google.com/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# OpenAI API Key
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI Base URL (optional, for OpenAI-compatible providers)
# Example for Fireworks AI: https://api.fireworks.ai/inference/v1
# OPENAI_BASE_URL=https://api.fireworks.ai/inference/v1

# ===========================
# Budget Configuration
# ===========================

# Maximum budget per task in USD (default: $1.00)
# Prevents runaway costs from infinite loops or excessive API calls
MAX_BUDGET_USD=1.00

# Pricing per 1M tokens for input (default: $0.075 for Gemini 2.0 Flash)
INPUT_PRICE_PER_1M=0.075

# Pricing per 1M tokens for output (default: $0.30 for Gemini 2.0 Flash)
OUTPUT_PRICE_PER_1M=0.30

# ===========================
# Agent Configuration
# ===========================

# Maximum steps per agent execution (default: 10)
# Prevents infinite loops in the CODE → EXECUTE → DECIDE cycle
MAX_AGENT_STEPS=10

# Maximum recursion depth for task delegation (default: 3)
# Controls how many levels of sub-tasks can be created
MAX_RECURSION_DEPTH=3

# ===========================
# DSPy Module Configuration
# ===========================

# Maximum retries for DSPy assertions (default: 3)
# When code generation fails validation, DSPy will retry up to this many times
MAX_DSPY_RETRIES=3

# ===========================
# Logging Configuration
# ===========================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (default: rlm_agent.log)
LOG_FILE=rlm_agent.log
